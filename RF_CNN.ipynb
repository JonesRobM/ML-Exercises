{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bab4f0",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs) and Their Application to RF Signal Analysis\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a class of deep learning models designed to automatically and adaptively learn spatial or temporal features from structured data. While widely used in image processing, CNNs are also effective for sequential data, including **radio frequency (RF) signals**, due to their ability to capture local dependencies and hierarchical patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. What is a CNN?\n",
    "\n",
    "A CNN is composed of several types of layers:\n",
    "\n",
    "1. **Convolutional Layers**  \n",
    "   - Apply learnable filters (kernels) across the input.  \n",
    "   - Each filter extracts local features, e.g., edges in images or patterns in RF waveforms.  \n",
    "   - Convolution preserves the local structure of the data.\n",
    "\n",
    "2. **Activation Functions**  \n",
    "   - Non-linear functions like ReLU (`f(x)=max(0,x)`) applied after convolution.  \n",
    "   - Introduce non-linearity, allowing the network to model complex patterns.\n",
    "\n",
    "3. **Pooling Layers**  \n",
    "   - Reduce the dimensionality of feature maps, typically via max or average pooling.  \n",
    "   - Retain dominant features and reduce computational complexity.\n",
    "\n",
    "4. **Fully Connected Layers**  \n",
    "   - Flatten the feature maps and perform classification or regression.  \n",
    "   - Combine features to produce the final output (e.g., modulation type or signal class).\n",
    "\n",
    "5. **Optional Layers**  \n",
    "   - Dropout, batch normalisation, and residual connections for regularisation and training stability.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Why CNNs for RF Signals?\n",
    "\n",
    "RF signals are typically represented as **time-series data**, often in the form of **I/Q samples** (in-phase and quadrature components). CNNs can extract meaningful features from these signals for tasks such as:\n",
    "\n",
    "- **Modulation recognition**: Determining the modulation scheme (e.g., BPSK, QPSK, 16-QAM).  \n",
    "- **Signal classification**: Identifying signal type or source (e.g., WiFi, LTE, radar).  \n",
    "- **Anomaly detection**: Detecting interference or unusual RF behaviour.  \n",
    "\n",
    "### Advantages of CNNs for RF:\n",
    "- Local correlations: Convolutional filters detect patterns in small windows of the waveform.  \n",
    "- Parameter efficiency: Shared weights reduce the number of parameters compared to fully connected networks.  \n",
    "- Hierarchical features: Low-level features (oscillations) combine into higher-level patterns (modulation shapes).  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Input Representation\n",
    "\n",
    "RF signals can be fed into a CNN in various forms:\n",
    "\n",
    "1. **Raw I/Q Time-Series**\n",
    "   - Shape: `(batch, 2, seq_len)` where 2 = I/Q channels.  \n",
    "   - Preserves phase and amplitude information.\n",
    "\n",
    "2. **Spectrograms or Time-Frequency Representations**\n",
    "   - Compute Short-Time Fourier Transform (STFT) to create a 2D representation.  \n",
    "   - Useful when frequency content is critical.  \n",
    "   - Can leverage 2D CNNs designed for images.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. CNN Architecture for RF Signals\n",
    "\n",
    "A typical CNN for RF signal classification includes:\n",
    "\n",
    "1. **1D Convolution Layers**  \n",
    "   - Detect patterns over small segments of the waveform.  \n",
    "   - Example: `Conv1d(in_channels=2, out_channels=16, kernel_size=5)`\n",
    "\n",
    "2. **Pooling Layers**  \n",
    "   - Reduce sequence length, keeping dominant features.\n",
    "\n",
    "3. **Fully Connected Layers**  \n",
    "   - Combine features to classify signals into desired categories.\n",
    "\n",
    "4. **Output Layer**  \n",
    "   - Typically a softmax layer for classification tasks.\n",
    "\n",
    "![CNN Architecture for RF Signal Classification](https://www.researchgate.net/profile/Qingjie-Yang/publication/361255771/figure/fig3/AS:1124262041185280@1656041345680/The-architecture-of-the-CNN-used-for-RF-signal-classification-Three-convolutional-layers.png)\n",
    "\n",
    "*Figure: CNN Architecture for RF Signal Classification. Three convolutional layers apply 32, 64, and 128 filters of size 3x3x3 pixels. Max-pooling reduces the sizes of the features by applying a local 2x3x2 maximum function. The final features are flattened and run through a fully connected layer before applying a SoftMax function. The final output consists of probabilities of being in one of the 17 classes of the database's UAVs.*\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Example Applications\n",
    "\n",
    "| Task | Input Type | CNN Approach |\n",
    "|------|------------|--------------|\n",
    "| Modulation Recognition | Raw I/Q samples | 1D CNN with convolution + pooling + fully connected layers |\n",
    "| Signal Source Classification | Time-frequency spectrogram | 2D CNN on spectrogram images |\n",
    "| Interference Detection | Raw I/Q or spectrum | CNN autoencoder or classifier for anomaly detection |\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Summary\n",
    "\n",
    "CNNs are a powerful tool for RF signal analysis because they:\n",
    "\n",
    "- Automatically learn features from raw data.\n",
    "- Capture local temporal dependencies in RF waveforms.\n",
    "- Scale efficiently to large datasets.\n",
    "- Can be applied to tasks such as modulation classification, signal detection, and interference identification.\n",
    "\n",
    "By representing RF signals appropriately (time-series or spectrogram) and designing suitable CNN architectures, practitioners can achieve high-performance classification and analysis without manual feature engineering.\n",
    "\n",
    "---\n",
    "\n",
    "**References**\n",
    "\n",
    "1. O'Shea, T. J., & Hoydis, J. (2017). *An Introduction to Deep Learning for the Physical Layer*. IEEE Transactions on Cognitive Communications and Networking, 3(4), 563–575.  \n",
    "2. Zhang, X., et al. (2018). *Convolutional Neural Networks for Modulation Recognition in Wireless Communications*. IEEE Wireless Communications Letters, 7(5), 862–865.  \n",
    "3. Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RFConvNet\n",
    "# =============================================================================\n",
    "# A bare-bones 1D convolutional neural network for RF signal classification.\n",
    "# Input: I/Q signal samples as (batch, 2, seq_len)\n",
    "# Output: Logits for classification into num_classes categories\n",
    "# =============================================================================\n",
    "class RFConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ## RFConvNet\n",
    "    1D CNN for RF signal analysis.\n",
    "\n",
    "    ### Arguments:\n",
    "    - num_classes (int): Number of output classes.\n",
    "    - seq_len (int): Length of input sequence (number of time steps).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=4, seq_len=128):\n",
    "        super(RFConvNet, self).__init__()\n",
    "        # First convolution: 2 input channels (I/Q), 16 output channels\n",
    "        self.conv1 = nn.Conv1d(2, 16, 5, padding=2)\n",
    "        # Second convolution: 16->32 channels\n",
    "        self.conv2 = nn.Conv1d(16, 32, 5, padding=2)\n",
    "        # Max pooling reduces sequence length by half\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * (seq_len // 4), 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # forward\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Computes the forward pass of the network.\n",
    "    #\n",
    "    # Input:\n",
    "    # - x (Tensor): shape (batch, 2, seq_len)\n",
    "    #\n",
    "    # Output:\n",
    "    # - Tensor: raw logits for each class\n",
    "    # -------------------------------------------------------------------------\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # flatten for fully connected layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# generate_dummy_dataset\n",
    "# =============================================================================\n",
    "# Creates a dummy I/Q dataset for training/testing purposes.\n",
    "# Replace with real RF dataset when available.\n",
    "# =============================================================================\n",
    "def generate_dummy_dataset(num_samples=500, seq_len=128, num_classes=4, batch_size=32):\n",
    "    \"\"\"\n",
    "    ## generate_dummy_dataset\n",
    "    Returns train and validation DataLoaders with random RF-like data.\n",
    "\n",
    "    ### Arguments:\n",
    "    - num_samples (int): Total number of samples.\n",
    "    - seq_len (int): Sequence length of each I/Q sample.\n",
    "    - num_classes (int): Number of output classes.\n",
    "    - batch_size (int): Batch size for DataLoader.\n",
    "\n",
    "    ### Returns:\n",
    "    - train_loader, val_loader (DataLoader, DataLoader)\n",
    "    \"\"\"\n",
    "    X = torch.randn(num_samples, 2, seq_len)\n",
    "    y = torch.randint(0, num_classes, (num_samples,))\n",
    "    dataset = TensorDataset(X, y)\n",
    "    train_size = int(0.8 * num_samples)\n",
    "    val_size = num_samples - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00cadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# train_and_validate\n",
    "# =============================================================================\n",
    "# Performs training and validation of the RF CNN.\n",
    "# Tracks loss, accuracy, confusion matrix, and classification report.\n",
    "# =============================================================================\n",
    "def train_and_validate(model, train_loader, val_loader, epochs=5, lr=1e-3, device=None):\n",
    "    \"\"\"\n",
    "    ## train_and_validate\n",
    "    Trains the model and evaluates it on a validation set.\n",
    "\n",
    "    ### Arguments:\n",
    "    - model (nn.Module): RFConvNet instance\n",
    "    - train_loader (DataLoader): Training data loader\n",
    "    - val_loader (DataLoader): Validation data loader\n",
    "    - epochs (int): Number of training epochs\n",
    "    - lr (float): Learning rate\n",
    "    - device (torch.device): CPU or CUDA device\n",
    "\n",
    "    ### Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training phase ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss /= total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # --- Validation phase ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                all_preds.append(predicted.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "\n",
    "        val_loss /= total\n",
    "        val_acc = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # --- Compute metrics ---\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(all_labels, all_preds))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Example usage\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model\n",
    "    model = RFConvNet(num_classes=4, seq_len=128)\n",
    "    # Generate dummy train/val data\n",
    "    train_loader, val_loader = generate_dummy_dataset(num_samples=500, seq_len=128, num_classes=4, batch_size=32)\n",
    "    # Train and validate\n",
    "    train_and_validate(model, train_loader, val_loader, epochs=5, lr=1e-3)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
