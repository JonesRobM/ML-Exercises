{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb8dbd37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a4c71c6",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks (PINNs) for Radio Frequency Signal Analysis\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Physics-Informed Neural Networks (PINNs) are a class of neural networks that integrate **physical laws** directly into the learning process. Unlike standard neural networks, which rely solely on data, PINNs enforce **governing equations** (e.g., differential equations) as part of the loss function. This allows the model to:\n",
    "\n",
    "- Respect physical constraints.\n",
    "- Reduce the need for large labelled datasets.\n",
    "- Generalise better in regions where data is sparse or noisy.\n",
    "\n",
    "In the context of radio frequency (RF) signal analysis, PINNs can model wave propagation, interference, and electromagnetic interactions while leveraging prior knowledge from Maxwell's equations or simplified wave equations.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Core Concept\n",
    "\n",
    "A PINN approximates the solution \\(u(x,t)\\) of a PDE by minimising a **composite loss function**:\n",
    "\n",
    "\\[\n",
    "\\mathcal{L} = \\mathcal{L}_{\\text{data}} + \\lambda \\mathcal{L}_{\\text{physics}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\(\\mathcal{L}_{\\text{data}} = \\frac{1}{N} \\sum_i \\left| u_\\text{pred}(x_i, t_i) - u_\\text{obs}(x_i, t_i) \\right|^2\\) is the standard supervised loss.\n",
    "- \\(\\mathcal{L}_{\\text{physics}} = \\frac{1}{M} \\sum_j \\left| \\mathcal{N}[u_\\text{pred}](x_j, t_j) \\right|^2\\) is the PDE residual loss.\n",
    "- \\(\\mathcal{N}[u]\\) represents the differential operator of the governing PDE (e.g., wave equation, Maxwell’s equations).\n",
    "\n",
    "The network is trained to **simultaneously fit the data and satisfy the physics** at collocation points.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Why PINNs for RF Signal Analysis\n",
    "\n",
    "RF signals propagate according to well-known physics (Maxwell's equations or their simplified forms). Challenges in RF signal modelling include:\n",
    "\n",
    "- Sparse or noisy measurements from antennas.\n",
    "- Complex boundary conditions (urban, indoor, or satellite environments).\n",
    "- Nonlinear effects in materials and media.\n",
    "\n",
    "PINNs offer:\n",
    "\n",
    "1. **Data efficiency:** Physical laws guide the network, reducing required labelled samples.\n",
    "2. **Generalisation:** Predicts fields in regions with no direct measurements.\n",
    "3. **Flexibility:** Can handle time-dependent, multi-dimensional, or coupled RF phenomena.\n",
    "4. **Integration of prior knowledge:** PDEs describing wave propagation, dispersion, or interference can be enforced explicitly.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Example: 1D Wave Propagation\n",
    "\n",
    "Consider a 1D RF wave \\(u(x,t)\\) governed by:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial^2 u}{\\partial t^2} = c^2 \\frac{\\partial^2 u}{\\partial x^2}\n",
    "\\]\n",
    "\n",
    "- **Inputs:** Spatial coordinate \\(x\\), time \\(t`  \n",
    "- **Output:** Field amplitude \\(u(x,t)\\)  \n",
    "- **Data loss:** Observed RF waveform samples at specific \\((x,t)\\)  \n",
    "- **Physics loss:** Residual of the wave equation at collocation points  \n",
    "\n",
    "The PINN learns a function \\(u_\\theta(x,t)\\) that fits the measurements while obeying the wave equation, enabling accurate interpolation and extrapolation of RF fields.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Diagram: RF Propagation and PINN Residuals\n",
    "\n",
    "      RF Source\n",
    "         |\n",
    "         v\n",
    "-------------------  <- Antenna/Environment\n",
    "| |\n",
    "| Field u(x,t) |\n",
    "| +----------------+----------------+\n",
    "| | Collocation points for PDE |\n",
    "| | residual enforcement |\n",
    "| +----------------+----------------+\n",
    "| |\n",
    "-------------------\n",
    "^\n",
    "|\n",
    "PINN predicts u(x,t)\n",
    "and enforces PDE residuals\n",
    "\n",
    "- **Blue points:** Observed RF data used for supervised loss.\n",
    "- **Red points:** Collocation points where PDE residual is enforced.\n",
    "- The network outputs \\(u_\\theta(x,t)\\) that satisfies both **data fit** and **physics**.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Extensions to Real-World RF Scenarios\n",
    "\n",
    "- **2D/3D propagation:** Model RF coverage in buildings, urban areas, or satellite footprints.  \n",
    "- **Nonlinear effects:** Incorporate material properties or interference.  \n",
    "- **Inverse problems:** Infer source positions or environmental parameters from observed signals.  \n",
    "- **Time-series analysis:** Combine with recurrent architectures for dynamic signals.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Summary\n",
    "\n",
    "PINNs bridge the gap between **data-driven learning** and **physics-based modelling**. In RF signal analysis, they enable:\n",
    "\n",
    "- Accurate modelling with limited data.\n",
    "- Enforcement of wave physics in complex environments.\n",
    "- Improved predictive capability in both observed and unobserved regions.\n",
    "\n",
    "By integrating PINNs into RF workflows, engineers and scientists can reduce reliance on dense measurements while maintaining physically consistent predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b02a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4730c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# PINN definition\n",
    "# -----------------\n",
    "# ## Class: PINN\n",
    "# Defines a fully connected neural network used as the physics-informed neural network (PINN).\n",
    "# - Input: (x, t)\n",
    "# - Output: u(x,t), the predicted RF field amplitude\n",
    "# - Architecture: feedforward MLP with tanh activations\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers)-1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i+1]))\n",
    "        self.activation = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = self.activation(layer(x))\n",
    "        return self.layers[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# PDE residual\n",
    "# -----------------\n",
    "# ## Function: wave_residual\n",
    "# Computes the residual of the 1D wave equation:\n",
    "#   u_tt - c^2 u_xx = 0\n",
    "# where:\n",
    "#   - u = model(x, t)\n",
    "#   - u_tt = second derivative wrt time\n",
    "#   - u_xx = second derivative wrt space\n",
    "#\n",
    "# Inputs:\n",
    "#   model: PINN instance\n",
    "#   x: spatial coordinate tensor\n",
    "#   t: temporal coordinate tensor\n",
    "#   c: wave propagation speed\n",
    "# Output:\n",
    "#   residual tensor\n",
    "def wave_residual(model, x, t, c=1.0):\n",
    "    # Concatenate inputs\n",
    "    xt = torch.cat([x, t], dim=1).requires_grad_(True)\n",
    "    u = model(xt)\n",
    "    \n",
    "    # First derivatives\n",
    "    u_t = autograd.grad(u, xt, torch.ones_like(u), retain_graph=True, create_graph=True)[0][:,1:2]\n",
    "    u_x = autograd.grad(u, xt, torch.ones_like(u), retain_graph=True, create_graph=True)[0][:,0:1]\n",
    "\n",
    "    # Second derivatives\n",
    "    u_tt = autograd.grad(u_t, xt, torch.ones_like(u_t), retain_graph=True, create_graph=True)[0][:,1:2]\n",
    "    u_xx = autograd.grad(u_x, xt, torch.ones_like(u_x), retain_graph=True, create_graph=True)[0][:,0:1]\n",
    "\n",
    "    # PDE residual: u_tt - c^2 u_xx = 0\n",
    "    return u_tt - (c**2) * u_xx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Training example\n",
    "# -----------------\n",
    "# ## Main block\n",
    "# Example training script:\n",
    "# - Defines a PINN with architecture [2, 50, 50, 50, 1]\n",
    "# - Creates synthetic RF signal data (sine wave)\n",
    "# - Samples collocation points for enforcing PDE residual\n",
    "# - Trains with Adam optimiser using combined data + physics loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Network: input (x,t) → output u(x,t)\n",
    "    model = PINN([2, 50, 50, 50, 1])\n",
    "    \n",
    "    # Optimiser\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Example training data (synthetic RF samples)\n",
    "    N_data = 100\n",
    "    x_data = torch.rand((N_data,1)) * 2 - 1  # domain [-1,1]\n",
    "    t_data = torch.rand((N_data,1)) * 1      # domain [0,1]\n",
    "    u_data = torch.sin(2*torch.pi*(x_data - t_data))  # synthetic RF waveform\n",
    "    \n",
    "    xt_data = torch.cat([x_data, t_data], dim=1)\n",
    "\n",
    "    # Collocation points for PDE residual\n",
    "    N_f = 1000\n",
    "    x_f = torch.rand((N_f,1)) * 2 - 1\n",
    "    t_f = torch.rand((N_f,1)) * 1\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(2000):\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Data loss\n",
    "        u_pred = model(xt_data)\n",
    "        loss_data = torch.mean((u_pred - u_data)**2)\n",
    "        \n",
    "        # Physics loss\n",
    "        f_pred = wave_residual(model, x_f, t_f, c=1.0)\n",
    "        loss_phys = torch.mean(f_pred**2)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = loss_data + loss_phys\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        if epoch % 200 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss={loss.item():.6f} Data={loss_data.item():.6f} Phys={loss_phys.item():.6f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
